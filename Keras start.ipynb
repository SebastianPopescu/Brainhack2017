{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import optimize\n",
    "from pylab import rcParams\n",
    "\n",
    "from sklearn.preprocessing import scale, StandardScaler\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "\n",
    "import gc\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.xception import Xception\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "def make_age_list(files, age_df):\n",
    "    age_list = []\n",
    "    for file in files:\n",
    "        ID = file[17:25]\n",
    "        age_list.append(df.loc[df[0] == ID][1].values[0])\n",
    "    return np.array(age_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_data(data, k, axis = 1):\n",
    "    #k - index of slice we are planning to use\n",
    "    #axis - type of slice (axial, sagittal, coronal)\n",
    "    \n",
    "    \n",
    "    #This is to normalize data before inputing it to NN\n",
    "    std = StandardScaler()\n",
    "    \n",
    "    # we make a mask to zero everythin with variance below some reasonable point\n",
    "    if axis == 0:\n",
    "        mask = np.var(data[:,k,:,:],0)\n",
    "    elif axis == 1:\n",
    "        mask = np.var(data[:,:,k,:],0)\n",
    "    else:\n",
    "        mask = np.var(data[:,:,:,k],0)\n",
    "    mask[mask < 0.000001] = 0\n",
    "    mask = ~mask.astype(bool)\n",
    "    \n",
    "    \n",
    "    if axis == 0:\n",
    "        new_data = np.zeros((data.shape[0], 145, 121, 3))\n",
    "        for i in range(3):\n",
    "            for j in range(121):\n",
    "                new_data[:,j,:,i] = std.fit_transform(data[:,k-10+10*i,j,:])\n",
    "            new_data[:,mask,i] = 0\n",
    "        new_data = new_data[:,12:133,:,:]\n",
    "    elif axis == 1:\n",
    "        new_data = np.zeros((data.shape[0], 121, 121, 3))\n",
    "        for i in range(3):\n",
    "            for j in range(121):\n",
    "                new_data[:,j,:,i] = std.fit_transform(data[:,j,k-10+10*i,:])\n",
    "            new_data[:,mask,i] = 0\n",
    "    elif axis == 2:\n",
    "        new_data = np.zeros((data.shape[0], 121, 145, 3))\n",
    "        for i in range(3):\n",
    "            for j in range(121):\n",
    "                new_data[:,j,:,i] = std.fit_transform(data[:,j,:,k-10+10*i])\n",
    "            new_data[:,mask,i] = 0\n",
    "        new_data = new_data[:,:,12:133,:]\n",
    "    return new_data.astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading the files\n",
    "folder_wm = 'wm_data_big'\n",
    "folder_gm = 'gm_data_big'\n",
    "\n",
    "df = pd.read_csv('BANC_2016.csv', header=None, sep=',')\n",
    "\n",
    "files_wm = os.listdir(folder_wm)\n",
    "files_gm = os.listdir(folder_gm)\n",
    "files_wm = sorted(files_wm)\n",
    "files_gm = sorted(files_gm)\n",
    "\n",
    "age = df[3]\n",
    "\n",
    "data = np.zeros((len(files_wm), 121,145,121), dtype = np.float32)\n",
    "\n",
    "for sub in tqdm(range(len(files_wm))):\n",
    "    ID = files_wm[sub]\n",
    "    img = nib.load(folder_wm + '/'+ID)\n",
    "    data[sub,...] = img.get_data()\n",
    "    \n",
    "    \n",
    "#prep_data is a list of preprocessed data. It will have length of 6 - \n",
    "#thirst 3 elements are 3 middle slices(axial, coronal, sagittal) of WM, next the same of GM\n",
    "\n",
    "prep_data = []\n",
    "prep_data.append(preprocess_data(data,60, 0))\n",
    "prep_data.append(preprocess_data(data,72, 1))\n",
    "prep_data.append(preprocess_data(data,60, 2))\n",
    "data = []\n",
    "\n",
    "#This is garbage collector, it clears RAM. Without this the code crashes on 32 GB of RAM, so we need this every\n",
    "#time we clear some variable, like just before a moment. \n",
    "gc.collect()\n",
    "\n",
    "data = np.zeros((len(files_wm), 121,145,121), dtype = np.float32)\n",
    "\n",
    "for sub in tqdm(range(len(files_gm))):\n",
    "    ID = files_gm[sub]\n",
    "    img = nib.load(folder_gm + '/'+ID)\n",
    "    data[sub,...] = img.get_data()\n",
    "    \n",
    "prep_data.append(preprocess_data(data,60, 0))\n",
    "prep_data.append(preprocess_data(data,72, 1))\n",
    "prep_data.append(preprocess_data(data,60, 2))\n",
    "data = []\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5.04090604312\n"
     ]
    }
   ],
   "source": [
    "# Baseline Ridge - we just use Ridge regression without pushig data trrough Xception. The result is not that bad\n",
    "\n",
    "\n",
    "kf = KFold(10)\n",
    "predicted_ages = np.zeros(age.shape[0])\n",
    "model = Ridge()\n",
    "features = np.concatenate([prep_data[0], prep_data[1], \n",
    "                              prep_data[2], prep_data[3],\n",
    "                          prep_data[4], prep_data[5]], 1)\n",
    "features = features.reshape(features.shape[0], np.prod(features.shape[1:]))\n",
    "features = features[:,:]\n",
    "for i_train, i_test in tqdm(kf.split(features, age)):\n",
    "    model.fit(features[i_train,:], age[i_train])\n",
    "    predicted_ages[i_test] = model.predict(features[i_test,:])\n",
    "print(MAE(age, predicted_ages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49140"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We make fatures by pushing our slices through 19 layers of xception\n",
    "\n",
    "xception = Xception(include_top=False, weights='imagenet', \n",
    "                        input_tensor=None, input_shape=(121,121,3), pooling=None, classes=1000)\n",
    "\n",
    "\n",
    "xception_model = Model(inputs=xception.input, outputs=xception.get_layer('block14_sepconv2_act').output)\n",
    "inp = xception_model.input                                           # input placeholder\n",
    "outputs = [xception.layers[19].output]     # all layer outputs\n",
    "functor = K.function([inp]+ [K.learning_phase()], outputs ) # evaluation function\n",
    "\n",
    "xception_features = []\n",
    "\n",
    "f_batch = 256\n",
    "features = np.zeros((2001, 14, 14, 256, 6))\n",
    "\n",
    "for i in tqdm(range(6)):\n",
    "    temp = np.zeros([prep_data[0].shape[0],] + xception.layers[19].output.get_shape().as_list()[1:])\n",
    "    for b in range((prep_data[0].shape[0]-1)//f_batch+1):\n",
    "        temp[f_batch*b:f_batch*(b+1), ...] = functor(\n",
    "            [prep_data[i][f_batch*b:f_batch*(b+1),:121,:121,:], 1.])[0]\n",
    "\n",
    "    #Here is max pooling. This should definitely be done in keras, but I was under heavy time constraint and this\n",
    "    #was just faster to code\n",
    "    temp = temp.reshape(temp.shape + (1,))\n",
    "    temp = np.max(np.concatenate([temp[:,2::2,...], temp[:,1::2,...]] , 4), 4)\n",
    "    temp = temp.reshape(temp.shape + (1,))\n",
    "    temp = np.max(np.concatenate([temp[:,:,:28:2,...], temp[:,:,1::2,...]] , 4), 4)\n",
    "    features[...,i] = temp\n",
    "temp = []\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4.17975930152\n"
     ]
    }
   ],
   "source": [
    "# Ridge on \"Xception preprocessed\" data\n",
    "gc.collect()\n",
    "\n",
    "kf = KFold(20, shuffle = True)\n",
    "\n",
    "predicted_ages = np.zeros(2001)\n",
    "\n",
    "model = Ridge()\n",
    "features = features.reshape(features.shape[0], np.prod(features.shape[1:]))\n",
    "# features = features[:,::3]\n",
    "gc.collect()\n",
    "for i_train, i_test in tqdm(kf.split(features, age)):\n",
    "    model.fit(features[i_train,:], age[i_train])\n",
    "    predicted_ages[i_test] = model.predict(features[i_test,:])\n",
    "print(MAE(age, predicted_ages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
